# pytorch-attention-Banhdanau-Luong
A PyTorch implementation of the Attention in "Effective Approaches to Attention-based Neural Machine Translation".

Banhdanau-attention
Luong-attention include Local-attention and Global-attention

I am a rookie, there may be errors, if you find out, please let me know
